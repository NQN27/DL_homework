{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-17T16:02:26.803214Z","iopub.status.busy":"2023-11-17T16:02:26.802917Z","iopub.status.idle":"2023-11-17T16:02:52.419064Z","shell.execute_reply":"2023-11-17T16:02:52.418150Z","shell.execute_reply.started":"2023-11-17T16:02:26.803163Z"},"trusted":true},"outputs":[],"source":["!pip install torchsummary torchgeometry torch pandas numpy==1.23.0 opencv-python wandb pillow imageio albumentations segmentation-models-pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:52.421267Z","iopub.status.busy":"2023-11-17T16:02:52.420946Z","iopub.status.idle":"2023-11-17T16:02:58.576022Z","shell.execute_reply":"2023-11-17T16:02:58.575294Z","shell.execute_reply.started":"2023-11-17T16:02:52.421239Z"},"trusted":true},"outputs":[],"source":["from torchsummary import summary\n","from torchgeometry.losses import one_hot\n","import os\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","import cv2\n","import time\n","import imageio\n","import matplotlib.pyplot as plt\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch import Tensor\n","from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n","from torchvision.transforms import Resize, PILToTensor, ToPILImage, Compose, InterpolationMode\n","from collections import OrderedDict\n","import wandb\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:58.577536Z","iopub.status.busy":"2023-11-17T16:02:58.577081Z","iopub.status.idle":"2023-11-17T16:02:59.540916Z","shell.execute_reply":"2023-11-17T16:02:59.539722Z","shell.execute_reply.started":"2023-11-17T16:02:58.577507Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:59.543882Z","iopub.status.busy":"2023-11-17T16:02:59.543545Z","iopub.status.idle":"2023-11-17T16:02:59.617519Z","shell.execute_reply":"2023-11-17T16:02:59.616580Z","shell.execute_reply.started":"2023-11-17T16:02:59.543856Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:59.619501Z","iopub.status.busy":"2023-11-17T16:02:59.618895Z","iopub.status.idle":"2023-11-17T16:02:59.635340Z","shell.execute_reply":"2023-11-17T16:02:59.634500Z","shell.execute_reply.started":"2023-11-17T16:02:59.619465Z"},"trusted":true},"outputs":[],"source":["# Number of class in the data set (3: neoplastic, non neoplastic, background)\n","num_classes = 3\n","\n","# Number of epoch\n","epochs = 15\n","\n","# Hyperparameters for training \n","learning_rate = 2e-04\n","\n","display_step = 50\n","\n","# Model path\n","checkpoint_path = '/kaggle/working/unet_model.pth'\n","pretrained_path = \"/kaggle/input/unet-checkpoint/unet_model.pth\"\n","# Initialize lists to keep track of loss and accuracy\n","loss_epoch_array = []\n","train_accuracy = []\n","test_accuracy = []\n","valid_accuracy = []"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:59.636635Z","iopub.status.busy":"2023-11-17T16:02:59.636376Z","iopub.status.idle":"2023-11-17T16:02:59.654654Z","shell.execute_reply":"2023-11-17T16:02:59.653723Z","shell.execute_reply.started":"2023-11-17T16:02:59.636613Z"},"trusted":true},"outputs":[],"source":["class UNetDataClass(Dataset):\n","    def __init__(self, images_path, masks_path, transform):\n","        super(UNetDataClass, self).__init__()\n","        self.img_dir = images_path\n","        self.label_dir = masks_path\n","        images_list = os.listdir(\"{}/\".format(images_path))\n","        masks_list = os.listdir(\"{}/\".format(masks_path))\n","        self.images = os.listdir(self.img_dir)\n","        images_list = [images_path + image_name for image_name in images_list]\n","        masks_list = [masks_path + mask_name for mask_name in masks_list]\n","        self.resize = (224,224)\n","        self.images_list = images_list\n","        self.masks_list = masks_list\n","        self.transform = transform\n","        \n","    def read_mask(self, mask_path):\n","        image = cv2.imread(mask_path)\n","        image = cv2.resize(image, self.resize)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","        # lower boundary RED color range values; Hue (0 - 10)\n","        lower1 = np.array([0, 100, 20])\n","        upper1 = np.array([10, 255, 255])\n","        # upper boundary RED color range values; Hue (160 - 180)\n","        lower2 = np.array([160,100,20])\n","        upper2 = np.array([179,255,255])\n","        lower_mask = cv2.inRange(image, lower1, upper1)\n","        upper_mask = cv2.inRange(image, lower2, upper2)\n","        \n","        red_mask = lower_mask + upper_mask\n","        red_mask[red_mask != 0] = 1\n","\n","        # boundary GREEN color range values; Hue (36 - 70)\n","        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n","        green_mask[green_mask != 0] = 2\n","\n","        full_mask = cv2.bitwise_or(red_mask, green_mask)\n","        full_mask = np.expand_dims(full_mask, axis=-1) \n","        full_mask = full_mask.astype(np.uint8)\n","        return full_mask\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.images[idx])\n","        label_path = os.path.join(self.label_dir, self.images[idx])\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        label = self.read_mask(label_path)\n","        image = cv2.resize(image, self.resize)\n","        if self.transform:\n","            transformed = self.transform(image=image, mask=label)\n","            image = transformed['image']\n","            label = transformed['mask']\n","        return image, label\n","    def __len__(self):\n","        return len(self.images_list)\n","    def show_image(self, idx):\n","        img_path = os.path.join(self.img_dir, self.images[idx])\n","        label_path = os.path.join(self.label_dir, self.images[idx])\n","        image = plt.imread(img_path)\n","        label = plt.imread(label_path)\n","        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n","        axs[0].imshow(image)\n","        axs[0].set_title('Image')\n","        axs[1].imshow(label)\n","        axs[1].set_title('Label')\n","        plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:59.656059Z","iopub.status.busy":"2023-11-17T16:02:59.655771Z","iopub.status.idle":"2023-11-17T16:02:59.668627Z","shell.execute_reply":"2023-11-17T16:02:59.667912Z","shell.execute_reply.started":"2023-11-17T16:02:59.656035Z"},"trusted":true},"outputs":[],"source":["images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train\"\n","masks_path =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:59.669903Z","iopub.status.busy":"2023-11-17T16:02:59.669641Z","iopub.status.idle":"2023-11-17T16:02:59.789617Z","shell.execute_reply":"2023-11-17T16:02:59.788821Z","shell.execute_reply.started":"2023-11-17T16:02:59.669881Z"},"trusted":true},"outputs":[],"source":["trainsize = 384\n","batch_size = 4\n","\n","unet_dataset = UNetDataClass(images_path= images_path,\n","                            masks_path= masks_path,\n","                             transform = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:59.790949Z","iopub.status.busy":"2023-11-17T16:02:59.790666Z","iopub.status.idle":"2023-11-17T16:02:59.803870Z","shell.execute_reply":"2023-11-17T16:02:59.802961Z","shell.execute_reply.started":"2023-11-17T16:02:59.790925Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(UNetDataClass):\n","    def __init__(self, dataset, transform=None):\n","        self.dataset = dataset\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        image, label = self.dataset[index] \n","        if self.transform:\n","            transformed = self.transform(image=image, mask=label)\n","            image = transformed['image']\n","            label = transformed['mask']\n","            label = label.permute(2,0,1)\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","train_transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n","    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n","    A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(), A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()]),\n","    A.Cutout(p=0.2, max_h_size=35, max_w_size=35, fill_value=255),\n","    A.ShiftScaleRotate(p=0.45, border_mode=cv2.BORDER_CONSTANT, rotate_limit=45, shift_limit=0.15, scale_limit=0.15),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    ToTensorV2(),\n","])\n","\n","val_transform = A.Compose([\n","    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n","    ToTensorV2(),\n","])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:59.807783Z","iopub.status.busy":"2023-11-17T16:02:59.807475Z","iopub.status.idle":"2023-11-17T16:02:59.816358Z","shell.execute_reply":"2023-11-17T16:02:59.815363Z","shell.execute_reply.started":"2023-11-17T16:02:59.807760Z"},"trusted":true},"outputs":[],"source":["train_size = 0.8\n","valid_size = 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:59.817603Z","iopub.status.busy":"2023-11-17T16:02:59.817340Z","iopub.status.idle":"2023-11-17T16:02:59.844035Z","shell.execute_reply":"2023-11-17T16:02:59.843324Z","shell.execute_reply.started":"2023-11-17T16:02:59.817571Z"},"trusted":true},"outputs":[],"source":["train_set, valid_set = random_split(unet_dataset, \n","                                    [int(train_size * len(unet_dataset)) , \n","                                     int(valid_size * len(unet_dataset))])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:59.845132Z","iopub.status.busy":"2023-11-17T16:02:59.844882Z","iopub.status.idle":"2023-11-17T16:02:59.851401Z","shell.execute_reply":"2023-11-17T16:02:59.850446Z","shell.execute_reply.started":"2023-11-17T16:02:59.845109Z"},"trusted":true},"outputs":[],"source":["train_dataset_not_aug = CustomDataset(train_set,\n","                             transform = val_transform)\n","train_dataset_aug = CustomDataset(train_set,\n","                             transform = train_transform)\n","val_dataset = CustomDataset(valid_set,\n","                             transform = val_transform)\n","\n","train_dataset_new = ConcatDataset([train_dataset_not_aug, train_dataset_aug])\n","\n","train_dataloader = DataLoader(train_dataset_new, batch_size= batch_size, shuffle= True)\n","valid_dataloader = DataLoader(val_dataset, batch_size= batch_size, shuffle= False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:02:59.852673Z","iopub.status.busy":"2023-11-17T16:02:59.852443Z","iopub.status.idle":"2023-11-17T16:03:00.310003Z","shell.execute_reply":"2023-11-17T16:03:00.309014Z","shell.execute_reply.started":"2023-11-17T16:02:59.852653Z"},"trusted":true},"outputs":[],"source":["image,label = train_dataset_new[0]\n","print('Image: ', image.shape, 'Label: ', label.shape)\n","\n","label_array = label.permute(1, 2, 0).numpy()\n","image_array = image.permute(1, 2, 0).numpy()\n","# Create a figure with 2 subplots (1 row, 2 columns)\n","fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n","\n","axs[0].imshow(image_array)\n","axs[0].set_title('Image')\n","axs[0].axis('off')  \n","\n","axs[1].imshow(label_array)\n","axs[1].set_title('Label')\n","axs[1].axis('off')  \n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:03:00.311557Z","iopub.status.busy":"2023-11-17T16:03:00.311209Z","iopub.status.idle":"2023-11-17T16:03:02.470052Z","shell.execute_reply":"2023-11-17T16:03:02.469234Z","shell.execute_reply.started":"2023-11-17T16:03:00.311526Z"},"trusted":true},"outputs":[],"source":["import segmentation_models_pytorch as smp\n","\n","model = smp.UnetPlusPlus(\n","    encoder_name=\"resnet18\",        \n","    encoder_weights=\"imagenet\",     \n","    in_channels=3,                  \n","    classes=3     \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:03:02.471508Z","iopub.status.busy":"2023-11-17T16:03:02.471204Z","iopub.status.idle":"2023-11-17T16:03:13.127107Z","shell.execute_reply":"2023-11-17T16:03:13.126022Z","shell.execute_reply.started":"2023-11-17T16:03:02.471482Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()\n","model = nn.DataParallel(model)\n","model.to(device)\n","\n","summary(model,(3, trainsize, trainsize))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:03:13.128685Z","iopub.status.busy":"2023-11-17T16:03:13.128369Z","iopub.status.idle":"2023-11-17T16:03:13.134560Z","shell.execute_reply":"2023-11-17T16:03:13.133612Z","shell.execute_reply.started":"2023-11-17T16:03:13.128657Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","learing_rate_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.6)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:03:13.136129Z","iopub.status.busy":"2023-11-17T16:03:13.135874Z","iopub.status.idle":"2023-11-17T16:03:13.147079Z","shell.execute_reply":"2023-11-17T16:03:13.146300Z","shell.execute_reply.started":"2023-11-17T16:03:13.136107Z"},"trusted":true},"outputs":[],"source":["checkpoint_path = '/kaggle/working/unet_model.pth'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:03:13.148419Z","iopub.status.busy":"2023-11-17T16:03:13.148118Z","iopub.status.idle":"2023-11-17T16:03:13.160596Z","shell.execute_reply":"2023-11-17T16:03:13.159715Z","shell.execute_reply.started":"2023-11-17T16:03:13.148395Z"},"trusted":true},"outputs":[],"source":["def save_model(model, optimizer, path):\n","    checkpoint = {\n","        \"model\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, path)\n","\n","def load_model(model, optimizer, path):\n","    checkpoint = torch.load(path)\n","    model.load_state_dict(checkpoint[\"model\"])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    return model, optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:05:16.415947Z","iopub.status.busy":"2023-11-17T16:05:16.414996Z","iopub.status.idle":"2023-11-17T16:05:16.429505Z","shell.execute_reply":"2023-11-17T16:05:16.428405Z","shell.execute_reply.started":"2023-11-17T16:05:16.415908Z"},"trusted":true},"outputs":[],"source":["# Train function for each epoch\n","def train(train_dataloader, valid_dataloader,learing_rate_scheduler, epoch, display_step):\n","    print(f\"Start epoch #{epoch+1}, learning rate for this epoch: {learing_rate_scheduler.get_last_lr()}\")\n","    start_time = time.time()\n","    train_loss_epoch = 0\n","    test_loss_epoch = 0\n","    last_loss = 999999999\n","    model.train()\n","    for i, (data,targets) in enumerate(train_dataloader):\n","        \n","        # Load data into GPU\n","        data, targets = data.to(device), targets.to(device)\n","        targets = targets.squeeze(dim=1).long()\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","\n","        # Backpropagation, compute gradients\n","        loss = loss_function(outputs, targets.long())\n","        loss.backward()\n","\n","        # Apply gradients\n","        optimizer.step()\n","        \n","        # Save loss\n","        train_loss_epoch += loss.item()\n","        if (i+1) % display_step == 0:\n","#             accuracy = float(test(test_loader))\n","            print('Train Epoch: {} [{}/{} ({}%)]\\tLoss: {:.4f}'.format(\n","                epoch + 1, (i+1) * len(data), len(train_dataloader.dataset), 100 * (i+1) * len(data) / len(train_dataloader.dataset), \n","                loss.item()))\n","                  \n","    print(f\"Done epoch #{epoch+1}, time for this epoch: {time.time()-start_time}s\")\n","    train_loss_epoch/= (i + 1)\n","    \n","    # Evaluate the validation set\n","    model.eval()\n","    with torch.no_grad():\n","        for data, target in valid_dataloader:\n","            data, target = data.to(device), target.to(device)\n","            target = target.squeeze(dim=1).long()\n","            test_output = model(data)\n","            test_loss = loss_function(test_output.float(), target.long())\n","            test_loss_epoch += test_loss.item()\n","            \n","    test_loss_epoch/= (i+1)\n","    \n","    return train_loss_epoch , test_loss_epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:03:13.175556Z","iopub.status.busy":"2023-11-17T16:03:13.175243Z","iopub.status.idle":"2023-11-17T16:03:13.187531Z","shell.execute_reply":"2023-11-17T16:03:13.186611Z","shell.execute_reply.started":"2023-11-17T16:03:13.175506Z"},"trusted":true},"outputs":[],"source":["# Test function\n","def test(dataloader):\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for i, (data, targets) in enumerate(dataloader):\n","            data, targets = data.to(device), targets.to(device)\n","            outputs = model(data)\n","            _, pred = torch.max(outputs, 1)\n","            test_loss += targets.size(0)\n","            correct += torch.sum(pred == targets).item()\n","    return 100.0 * correct / test_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:03:13.188892Z","iopub.status.busy":"2023-11-17T16:03:13.188579Z","iopub.status.idle":"2023-11-17T16:03:47.407265Z","shell.execute_reply":"2023-11-17T16:03:47.406306Z","shell.execute_reply.started":"2023-11-17T16:03:13.188868Z"},"trusted":true},"outputs":[],"source":["wandb.login(\n","    # set the wandb project where this run will be logged\n","#     project= \"PolypSegment\", \n","    key = \"6d40f93d347a292e10474bc6fb74d8288f5de83b\",\n",")\n","wandb.init(\n","    project = \"PolypSegment\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T16:05:25.955449Z","iopub.status.busy":"2023-11-17T16:05:25.954681Z","iopub.status.idle":"2023-11-17T16:05:49.436703Z","shell.execute_reply":"2023-11-17T16:05:49.435128Z","shell.execute_reply.started":"2023-11-17T16:05:25.955418Z"},"trusted":true},"outputs":[],"source":["loss_function = nn.CrossEntropyLoss()\n","# Training loop\n","train_loss_array = []\n","test_loss_array = []\n","last_loss = 9999999999999\n","for epoch in range(epochs):\n","    train_loss_epoch = 0\n","    test_loss_epoch = 0\n","    (train_loss_epoch, test_loss_epoch) = train(train_dataloader, \n","                                              valid_dataloader, \n","                                              learing_rate_scheduler, epoch, display_step)\n","    \n","    if test_loss_epoch < last_loss:\n","        save_model(model, optimizer, checkpoint_path)\n","        last_loss = test_loss_epoch\n","        \n","    learing_rate_scheduler.step()\n","    train_loss_array.append(train_loss_epoch)\n","    test_loss_array.append(test_loss_epoch)\n","    wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch})\n","    #train_accuracy.append(test(train_loader))\n","    #valid_accuracy.append(test(test_loader))\n","    #print(\"Epoch {}: loss: {:.4f}, train accuracy: {:.4f}, valid accuracy:{:.4f}\".format(epoch + 1, \n","     #                                   train_loss_array[-1], train_accuracy[-1], valid_accuracy[-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:03:49.033901Z","iopub.status.idle":"2023-11-17T16:03:49.034307Z","shell.execute_reply":"2023-11-17T16:03:49.034120Z","shell.execute_reply.started":"2023-11-17T16:03:49.034102Z"},"trusted":true},"outputs":[],"source":["!mkdir predicted_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:03:49.035419Z","iopub.status.idle":"2023-11-17T16:03:49.036113Z","shell.execute_reply":"2023-11-17T16:03:49.035889Z","shell.execute_reply.started":"2023-11-17T16:03:49.035866Z"},"trusted":true},"outputs":[],"source":["color_dict= {0: (0, 0, 0),\n","             1: (255, 0, 0),\n","             2: (0, 255, 0)}\n","def mask_to_rgb(mask, color_dict):\n","    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n","#     print(output.shape)\n","    for k in color_dict.keys():\n","        output[mask==k] = color_dict[k]\n","\n","    return np.uint8(output)    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:03:49.037503Z","iopub.status.idle":"2023-11-17T16:03:49.037994Z","shell.execute_reply":"2023-11-17T16:03:49.037765Z","shell.execute_reply.started":"2023-11-17T16:03:49.037741Z"},"trusted":true},"outputs":[],"source":["model.eval()\n","for i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n","    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n","    ori_img = cv2.imread(img_path)\n","    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n","    ori_w = ori_img.shape[0]\n","    ori_h = ori_img.shape[1]\n","    img = cv2.resize(ori_img, (trainsize, trainsize))\n","    transformed = val_transform(image=img)\n","    input_img = transformed[\"image\"]\n","    input_img = input_img.unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n","    mask = cv2.resize(output_mask, (ori_h, ori_w))\n","    mask = np.argmax(mask, axis=2)\n","    mask_rgb = mask_to_rgb(mask, color_dict)\n","    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n","    cv2.imwrite(\"predicted_mask/{}\".format(i), mask_rgb)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:03:49.039574Z","iopub.status.idle":"2023-11-17T16:03:49.040017Z","shell.execute_reply":"2023-11-17T16:03:49.039810Z","shell.execute_reply.started":"2023-11-17T16:03:49.039788Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import os\n","\n","def rle_to_string(runs):\n","    return ' '.join(str(x) for x in runs)\n","\n","def rle_encode_one_mask(mask):\n","    pixels = mask.flatten()\n","    pixels[pixels > 225] = 255\n","    pixels[pixels <= 225] = 0\n","    use_padding = False\n","    if pixels[0] or pixels[-1]:\n","        use_padding = True\n","        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n","        pixel_padded[1:-1] = pixels\n","        pixels = pixel_padded\n","    \n","    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n","    if use_padding:\n","        rle = rle - 1\n","    rle[1::2] = rle[1::2] - rle[:-1:2]\n","    return rle_to_string(rle)\n","\n","def rle2mask(mask_rle, shape=(3,3)):\n","    '''\n","    mask_rle: run-length as string formated (start length)\n","    shape: (width,height) of array to return \n","    Returns numpy array, 1 - mask, 0 - background\n","\n","    '''\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape).T\n","\n","def mask2string(dir):\n","    ## mask --> string\n","    strings = []\n","    ids = []\n","    ws, hs = [[] for i in range(2)]\n","    for image_id in os.listdir(dir):\n","        id = image_id.split('.')[0]\n","        path = os.path.join(dir, image_id)\n","        print(path)\n","        img = cv2.imread(path)[:,:,::-1]\n","        h, w = img.shape[0], img.shape[1]\n","        for channel in range(2):\n","            ws.append(w)\n","            hs.append(h)\n","            ids.append(f'{id}_{channel}')\n","            string = rle_encode_one_mask(img[:,:,channel])\n","            strings.append(string)\n","    r = {\n","        'ids': ids,\n","        'strings': strings,\n","    }\n","    return r\n","\n","\n","MASK_DIR_PATH = '/kaggle/working/predicted_mask' # change this to the path to your output mask folder\n","dir = MASK_DIR_PATH\n","res = mask2string(dir)\n","df = pd.DataFrame(columns=['Id', 'Expected'])\n","df['Id'] = res['ids']\n","df['Expected'] = res['strings']\n","\n","df.to_csv(r'output.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":2715462,"sourceId":30892,"sourceType":"competition"},{"datasetId":3984786,"sourceId":6938815,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
